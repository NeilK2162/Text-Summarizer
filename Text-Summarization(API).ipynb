{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CLytLpcrwL_",
        "outputId": "d83cdde5-910d-420a-9a3b-69cc755b6483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.5 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install PyPDF2\n",
        "!pip install PyMuPDF\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-cnn\"\n",
        "headers = {\"Authorization\": \"Bearer xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}\n"
      ],
      "metadata": {
        "id": "8WWTNhOQsADu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        ""
      ],
      "metadata": {
        "id": "8qHvNZ-esKY2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import re\n",
        "import requests\n",
        "\n",
        "def extract_sections_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "\n",
        "    sections = []\n",
        "    current_section = {\"title\": \"\", \"content\": \"\"}\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        page_text = page.get_text()\n",
        "\n",
        "        for line in page_text.split('\\n'):\n",
        "            # You may need to adjust this regular expression to match your heading or bold text style\n",
        "            heading_pattern = re.compile(r'^[A-Z].*\\s*$')  # Example: Capitalized text\n",
        "            is_heading = heading_pattern.match(line)\n",
        "            if is_heading:\n",
        "                if current_section[\"title\"]:\n",
        "                    sections.append(current_section)\n",
        "                current_section = {\"title\": line, \"content\": \"\"}\n",
        "\n",
        "                # Check if the section title is \"References\" and break out of the loop\n",
        "                if line.strip().lower() == \"references\":\n",
        "                    return sections\n",
        "            else:\n",
        "                current_section[\"content\"] += line\n",
        "\n",
        "    if current_section[\"title\"]:\n",
        "        sections.append(current_section)\n",
        "\n",
        "    return sections\n"
      ],
      "metadata": {
        "id": "yZXieZKrsRZc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import concurrent.futures\n",
        "import time\n",
        "\n",
        "# URL of the PDF file you want to download\n",
        "pdf_url = \"https://arxiv.org/pdf/2112.07443.pdf\"\n",
        "\n",
        "# Define the function to process a section\n",
        "def process_section(section, output):\n",
        "    word_count = len(section['content'].split())\n",
        "    if word_count > 20:\n",
        "        time.sleep(11)\n",
        "        return query(section['content'])\n",
        "    else:\n",
        "        return section['content']\n",
        "\n",
        "# Download the PDF file\n",
        "response = requests.get(pdf_url)\n",
        "\n",
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # Specify the local file path where you want to save the PDF\n",
        "    local_pdf_path = \"temp.pdf\"\n",
        "\n",
        "    # Save the PDF content to a local file\n",
        "    with open(local_pdf_path, \"wb\") as pdf_file:\n",
        "        pdf_file.write(response.content)\n",
        "\n",
        "    # Now that you have saved the PDF, you can extract sections from it\n",
        "    sections = extract_sections_from_pdf(local_pdf_path)\n",
        "\n",
        "    # Create a list of outputs\n",
        "    outputs = [None, None, None, None]\n",
        "\n",
        "    # Create a ThreadPoolExecutor with 4 worker threads\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
        "        for i in range(0, len(sections), 4):\n",
        "            futures = []\n",
        "            for j in range(4):\n",
        "                if i + j < len(sections):\n",
        "                    futures.append(executor.submit(process_section, sections[i + j], outputs[j]))\n",
        "\n",
        "            for j, future in enumerate(futures):\n",
        "                section = sections[i + j]\n",
        "                if section['title'].strip().lower() == \"references\":\n",
        "                  break\n",
        "                print(f\"{section['title']} \")\n",
        "                result = future.result()\n",
        "                if isinstance(result, str):\n",
        "                    print(result)  # Print the text directly\n",
        "                elif isinstance(result, list) and result:  # Assuming it's a list of dictionaries\n",
        "                    print(result[0].get('summary_text', ''))\n",
        "                else:\n",
        "                    print(\"Unknown output format\")\n",
        "else:\n",
        "    print(\"Failed to download the PDF. Status code:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iTjkPZosUKE",
        "outputId": "7943cef4-a07d-4aa5-9160-d829b3a836cd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Classiﬁcation Models for Form Entity \n",
            "\n",
            "Linking⋆ \n",
            "\n",
            "María Villota1[0000−0002−1457−4270], César Domínguez1[0000−0002−2081−7523], \n",
            "\n",
            "Jónathan Heras1[0000−0003−4775−1306], Eloy Mata1[0000−0003−0538−4579], and \n",
            "\n",
            "Vico Pascual1[0000−0003−3576−0889] \n",
            "\n",
            "Department of Mathematics and Computer Science, University of La Rioja, Spain \n",
            "{maria.villota, cesar.dominguez, jonathan.heras, eloy.mata,vico.pascual}@unirioja.es\n",
            "Abstract. Forms are a widespread type of template-based document \n",
            "Forms. used in a great variety of ﬁelds including, among others, administra-tion, medicine, and insurance. In this con-text, there is a feature that is shared by all forms: they contain a col-lection of interlinked entities built as key-value (or label-value) pairs.\n",
            "BERT architecture. This approach achieves state-of-the-art results with \n",
            "A 5% improvement over the best previous method. a F1-score of 0.80 on the FUNSD dataset. The code of this project is available athttps://github.com/mavillot/FUNSD-Entity-Linking. Back to Mail Online home. back to the page you came from.\n",
            "Keywords: Entity Linking· Text Classiﬁcation · Deep learning \n",
            "1\n",
            "Introduction \n",
            "\n",
            "Forms are template-based documents that contain a collection of interlinked en- \n",
            "Forms are a convenient way to collect and communicate data in lots of ﬁelds. There is an enormous demand in digitising forms and extracting the data included in them. The formunderstanding task is especially challenging when working with scanned docu-ments due to the diversity of templates, structures, layouts, and formats.\n",
            "Grant \n",
            "\n",
            "RTC-2017-6640-7; \n",
            "andby\n",
            "MCIN/AEI/10.13039/501100011033, under Grant PID2020-115225RB-I00. \n",
            "arXiv:2112.07443v1  [cs.CL]  14 Dec 20212\n",
            "M. Villota et al. \n",
            "greatly vary among forms; and, also due to the diﬀerent quality of the scanneddocument images [22].\n",
            "Form understanding consists of two steps: form entity recognition and form \n",
            "The spatial layout and written information offorms are analysed to localise the position of form entities and to identify them. In thelatter step, the extracted entities are interlinked to understand their relation-ships. Several approaches have been published in the literature in order to solveboth tasks.\n",
            "In this work, we have focused on the problem of entity linking in forms using \n",
            "We have proposed a new method for the task of entity linking in forms thatcombines image processing techniques and a text classiﬁcation model. The best model was obtained using the BERT architec-ture [6], which achieved a F1-score of 0.80; a 5% improvement regarding the previous method.\n",
            "The rest of the paper is organised as follow. In the next section, we describe \n",
            "In Section 3, we conduct a literature review and analyseexisting approaches to solve the task of form entity linking. The main featuresof our method are detailed in Section 4, and a description of the obtained results is included in Section 5. This section also includes a comparison of our resultswith the results obtained by other methods on the FUNSD dataset. The paperends with a conclusions and further work section.\n",
            "The FUNSD dataset \n",
            "\n",
            "Form understanding is a task that, up to now, has received little attention in the \n",
            "The scarcity of works in this area is mainly based on the absence ofdatasets of forms. Such an absence was due to the sensitive information included in these documents. The FUNSD dataset was the ﬁrst publiclyavailable dataset that was developed with form understanding purposes.\n",
            "FUNSD dataset is a fully annotated dataset of scanned forms from noisy and \n",
            "old documents. Moreover, baselines and metrics for the tasks of form entityrecognition and form entity linking were provided.\n",
            "The FUNSD Datatet [12] is freely available, and it contains 199 fully an- \n",
            "notated images of forms that vary widely with respect to their structure and\n",
            "Text Classiﬁcation Models for Form Entity Linking \n",
            "The forms come from diﬀerent ﬁelds, e.g., marketing, advertising,and scientiﬁc reports. They were sampled from the form type document of the RVL-CDIP dataset. The documents have a quality with various types of noise addedby successive scanning and printing procedures.\n",
            "A semantic entity is described by a unique identiﬁer, a label (chosen from four \n",
            "The dataset is split into 149 images in thetraining set and 50 in the testing set. The 199 annotated forms contain more that 30,000 word-level annotations,9,000 entities, and 5,000 relations. The training set includes 149 images, and the test set includes 50 images.\n",
            "In order to evaluate the tasks of form entity recognition and form entity \n",
            "F1-score, mean linking, and F2-score are just a few of the metrics used in the FUNSD dataset. We focus on those related to the task of form entity linking that are F1- Score, mean Linking, F2 Linking and F3 Linking.\n",
            "Average Precision (mAP) and mean Rank (mRank) [20]. These metrics are based \n",
            "The True Positive value (TP) is the number of linksbetween a question and an answer that are correctly predicted. The False Positive(FP) value is the. number of predicted links that do not exist. Finally,the number of unlinked answers and questions that are. correctly predicted is the True Negative (FN)\n",
            "True Negative (TN) value. From these values the recall, precison and F1-score \n",
            "metrics are deﬁned as follows:recall =\n",
            "TP \n",
            "\n",
            "TP + FN , precision = \n",
            "\n",
            "TP \n",
            "\n",
            "TP + FP , F1-score = 2· (precision · recall) \n",
            "(precision + recall)\n",
            "In addition to the F1-score, other two metrics, called mAP and mRank, have \n",
            "mAP and mRank are metrics used that come from the context of object detection. The larger the mAP value, the better. mRank measures the average number of wrong answers that rank higherthan right answers. been used in the literature to evaluate form entity linking algorithms.\n",
            "AP = \n",
            "MAP is the precision and recall at the nth threshold. The mAP value is obtained by computing themean value of all the APs values. �n(Rn − Rn−1)Pnwhere Pn and Rn are the Precision and Recall at the Nthreshold.\n",
            "Finally, the mRank metric is deﬁned as follows. Given an answer x that has \n",
            " n candidate questions, y1, y2, . . . , yn, and among them m are correct (in FUNSDm ≤ 2) with indices i1, i2,  im in an ascending order, the mRank metric is4. If i1 is correct and i2 is correct, then im is correct as well.\n",
            "M. Villota et al. \n",
            "For the ﬁrst answer yi1, the number of wrong answers thatrank higher than it is i1 − 1. For the second one, yi2, is i2 − 2. Then, the Rankvalue is deﬁned as:\n",
            "Rank = \n",
            "mRank value is the mean value of the Rank values obtained from eachanswer. m�k=1ik − k =m�k =1ik + (1 + m)m2 and k =k + 1ik + mm2. mRank is the sum of the mean values of each answer's Rank.\n",
            "Related work \n",
            "\n",
            "Since its publication, the FUNSD dataset has been used as a benchmark by \n",
            "With this dataset, the increased interest in automatic informa-tion extraction from semi-structured documents has been translated to formunderstanding. Inthis section, we provide a summary of the diﬀerent approaches existing in theliterature to tackle the task of form entity linking using the FUNSD dataset.\n",
            "The authors of the FUNSD dataset [12] not only provided such a dataset, \n",
            "Method consisted inconcatenating the entity feature representation (extracted using the pretrainedlanguage model BERT [6]) of every pair of entities in the form. This baseline method achieved a F1-score of 0.04. Fromthat seminal work, several methods for entity linking have been developed in theliterature.\n",
            "In [20], a multimodal method to extract key-values pairs and build the hi- \n",
            " erarchical structure in documents for form entity linking was proposed. The form structure was considered as a tree-like hierarchy of text fragments, and the parent-child relation corresponded to key-value pairs in forms. The multi-modal method included information from three sources: semantic features forthe text fragments using a pre-trained language model (such as, BERT [6] or\n",
            "RoBerta [14]), layout information showing the size and relative location of the \n",
            "The method was applied to the FUNSD dataset and it obtained a mAP of 0.72. An ablation study showed that the semantic and spatial features were the most valuable for completing the task. The combination of mul-tiple aspects of forms was also used in [9], where the authors created a modelcalled BROS.\n",
            "Text Classiﬁcation Models for Form Entity Linking \n",
            "The model was applied to form entity linking on the FUNSD dataset and it obtained a F1-score of 0.67. 5scanned documents. Then, the model was ﬁne-tuned using the embeddings ondiﬀerent contexts.\n",
            "A diﬀerent approach was proposed in [1]. In this work, a graph neural net- \n",
            " work was used to predict links between entities. In this approach, the documentwas represented as a graph whose nodes were the words previously provided by the author. The nodes of the graph were then used to create a graph of the words in the document. For more information on this project, visit: http://www.cnn.com/2013/01/30/science/science-and-technology/science_and technology/how-to- predict-links-between- entities-by-using-a-graph.\n",
            "OCR, and the edges were initially created based on the distances of the top-left \n",
            "This model obtained a F1-score of 0.39 in theentity linking task on the FUNSD dataset. On the contrary to the works [9,20]that required a pre-training stage, this model only used FUNSD data to trainit. A similar approach was used in [5] where a model named FUDGE using agraph neural network was proposed.\n",
            "FUDGE only used a purely visual solution (without including any language in- \n",
            "FUDGE didnot use any additional data from FUNSD in the training process. This modelsobtained a F1-score of 0.57 in the entity linking task. It included an iterative method to allow the model to mergevertices and prune edges.\n",
            "Finally, other three diﬀerent approaches have been presented in the literature \n",
            "The authors of [11] tackled thetask of extracting information from a form as a dependency graph parsing prob-lem. This work deﬁnes a model named SPADE. to solve the problem of form entity linking. This model createda directed semantic relation graph of the tokens in the document using both lin-guistic and (two-dimensional) spatial information.\n",
            "This model was trained to solve the entity linking problem on FUNSD dataset \n",
            "In [16] a multi-task learning method wasapplied to form understanding. In this method, a model was deﬁned to jointlylearn three tasks simultaneously: word grouping, entity labelling, and entity link-ing. The idea was that the learning of the former two tasks (that were considered auxiliary tasks) forced the model to learn to identify characteristics of the dif-ferent entities types.\n",
            "The proposed model leveraged a specialised multi-stage encoder-decoder design, \n",
            "The method incorporated further. in conjunction with an eﬃcient use of a self-attention mechanism and a boxconvolution. to capture the textual and spatial relations between 2Delements for solving entity labelling. It was developed by the University of California, San Diego.\n",
            "M. Villota et al. \n",
            "This model was trained in FUNSD to solve together the classiﬁ-cation and link prediction tasks. It obtained in the entity linking problem a a part-intensity ﬁelds and part-association ﬅlds. This last method was inspired by the techniques used in human poseestimation [4].\n",
            "F1-score of 0.75. \n",
            "4\n",
            "Methods \n",
            "\n",
            "In this section, we present how we have combined image processing techniques \n",
            "We use a combination of form entity linking. and deep learning methods to perform the task. For each answer that is found on a given form, weidentify a set of candidate questions based on their distance to the answer. We concatenate the text of each candidate question with the answer, and use a text classiﬁcation model to determine if that combinationof question and answer makes sense.\n",
            "Fig. 1. Pipeline of the proposed method. (1) From an answer, a set of candidate ques- \n",
            "Each combination of candidate question-answer is fed to a textclassiﬁcation model. The model identifies the valid combinations of question- answer. tions are then used to create a text classi ﬉cation model for each question. The text class is then fed into the text class to create the textclass model.\n",
            "If more than one combination is valid, we apply a set of rules based on the distance \n",
            "between the question and the answer. (5) Finally, the results are returned.\n",
            "Text Classiﬁcation Models for Form Entity Linking \n",
            "7\n",
            "Now, we present how we have built the text classiﬁcation model that deter- \n",
            "Text classiﬁcation is anatural language processing task. It consists in categorising a text into a set of prede ﬁned classes. Nowadays, this task is mainly tackled using deep learning models. Since it is not feasible to train this kind of model from scratch, we have applied transfer learning.\n",
            "For our text classiﬁcation models, we have ﬁne-tuned several transformer- \n",
            "based language architectures; namely, BERT [6], DistilBert [18], Roberta [14],\n",
            "DistilRoberta [18], and LayoutLM [22]. For ﬁne-tuning the models, we replaced \n",
            "All the networks used in ourexperiments were implemented in Pytorch [15], and have been trained thanksto the functionality of the libraries Hugging Face [21], FastAI [10] and Blur [7]using the GPUs provided by the Google Colab environment.\n",
            "Results \n",
            "\n",
            "In this section, we analyse the results achieved with our method. We start by \n",
            "exploring the performance of the studied text classiﬁcation model, see Table 1.\n",
            "The best model for all the evaluated metrics is obtained using the BERT archi- \n",
            "tecture. This model clearly overcomes the rest by a large margin, it achieves a\n",
            "F1-score of 0.80; whereas, the rest of the models obtain values lower than 0.70. \n",
            "mAP mRank F1-score\n",
            "BERT \n",
            "0.870.490.80\n",
            "DistilBERT \n",
            "0.790.790.68\n",
            "DistilRoBerta 0.76 \n",
            "0.950.65\n",
            "LayoutLM \n",
            "0.790.810.69\n",
            "RoBerta \n",
            "0.770.940.66\n",
            "Table 1. Results achieved for entity linking by the tested text classiﬁcation models. \n",
            "\n",
            "In bold face the best results. \n",
            "\n",
            "We additionally compare our proposed method with the existing algorithms \n",
            "Our method obtains a better mAP and mRank than thealgorithms available in the literature. This proves the eﬀectiveness of combiningimage processing techniques and deep learning models in this context. We conclude that the performance of our method using the BERT model improves all the existing approaches.\n",
            "M. Villota et al. \n",
            "mAP mRank F1-score\n",
            "BROS [9] \n",
            "--0.67\n",
            "Carbonell et al. [1] \n",
            "--0.39\n",
            "FUDGE [5] \n",
            "--0.62\n",
            "FUNSD paper [12] \n",
            "0.2311.680.04\n",
            "DocStruct Model [20] \n",
            "0.722.89-\n",
            "LayoutLM Word Level [16] 0.47 \n",
            "7.11-\n",
            "MSAU-PAF [4] \n",
            "--0.75\n",
            "MTL-FoUn [16] \n",
            "0.711.320.65\n",
            "Sequential Model [16] \n",
            "0.651.450.61\n",
            "SPADE [11] \n",
            "--0.41\n",
            "Ours \n",
            "0.870.490.80\n",
            "Table 2. Comparison of our approach with existing methods for entity linking. In bold \n",
            "face the best results.6\n",
            "Conclusion and Further work \n",
            "\n",
            "In this paper, we have proposed a method for form entity linking based on \n",
            "the combination of image processing techniques and text classiﬁcation models.\n",
            "We tested several transformer-based models for text classiﬁcation and reached \n",
            "This approach has achieved state-of-the-art results for form entity linking in the FUNSD dataset. It shows the beneﬁts of combining deep learning models with algorithms based on the existing knowledge about documents when working in contexts where annotated data is scarce.\n",
            "As further work, we are interested in applying our method to more recent \n",
            "We plan to adapt our approach to work with documents written on diﬀerentlanguages. The mainchallenges here are the privacy concerns raised when using form documents, and issues related to the annotation of these documents, a time-consuming taskthat is instrumental to train and evaluate any deep learning model.\n"
          ]
        }
      ]
    }
  ]
}